{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch=250\n",
    "batch_size=128\n",
    "verbose=1\n",
    "nb_classes=10\n",
    "optimizer=SGD()\n",
    "n_hidden=128\n",
    "validation_split=0.2\n",
    "dropout=0.3\n",
    "reshaped=784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,784)\n",
    "x_test=x_test.reshape(10000,784)\n",
    "x_train=x_train.astype(\"float32\")\n",
    "x_test=x_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train/=255\n",
    "x_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train,nb_classes)\n",
    "y_test=np_utils.to_categorical(y_test,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 2.3008 - acc: 0.1200 - val_loss: 2.3005 - val_acc: 0.1060\n",
      "Epoch 2/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 2.2998 - acc: 0.1140 - val_loss: 2.3003 - val_acc: 0.1060\n",
      "Epoch 3/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2995 - acc: 0.1140 - val_loss: 2.3002 - val_acc: 0.1060\n",
      "Epoch 4/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2993 - acc: 0.1140 - val_loss: 2.3002 - val_acc: 0.1060\n",
      "Epoch 5/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2992 - acc: 0.1140 - val_loss: 2.3001 - val_acc: 0.1060\n",
      "Epoch 6/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2992 - acc: 0.1140 - val_loss: 2.3001 - val_acc: 0.1060\n",
      "Epoch 7/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2991 - acc: 0.1140 - val_loss: 2.3000 - val_acc: 0.1060\n",
      "Epoch 8/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2990 - acc: 0.1140 - val_loss: 2.2999 - val_acc: 0.1060\n",
      "Epoch 9/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2989 - acc: 0.1140 - val_loss: 2.2999 - val_acc: 0.1060\n",
      "Epoch 10/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2988 - acc: 0.1140 - val_loss: 2.2998 - val_acc: 0.1060\n",
      "Epoch 11/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2987 - acc: 0.1140 - val_loss: 2.2997 - val_acc: 0.1060\n",
      "Epoch 12/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2987 - acc: 0.1140 - val_loss: 2.2995 - val_acc: 0.1060\n",
      "Epoch 13/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2986 - acc: 0.1140 - val_loss: 2.2994 - val_acc: 0.1060\n",
      "Epoch 14/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2985 - acc: 0.1140 - val_loss: 2.2994 - val_acc: 0.1060\n",
      "Epoch 15/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2984 - acc: 0.1140 - val_loss: 2.2992 - val_acc: 0.1060\n",
      "Epoch 16/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2983 - acc: 0.1140 - val_loss: 2.2991 - val_acc: 0.1060\n",
      "Epoch 17/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2981 - acc: 0.1140 - val_loss: 2.2990 - val_acc: 0.1060\n",
      "Epoch 18/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2980 - acc: 0.1140 - val_loss: 2.2989 - val_acc: 0.1060\n",
      "Epoch 19/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2979 - acc: 0.1140 - val_loss: 2.2988 - val_acc: 0.1060\n",
      "Epoch 20/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2978 - acc: 0.1140 - val_loss: 2.2987 - val_acc: 0.1060\n",
      "Epoch 21/250\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 2.2977 - acc: 0.1140 - val_loss: 2.2986 - val_acc: 0.1060\n",
      "Epoch 22/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2976 - acc: 0.1140 - val_loss: 2.2986 - val_acc: 0.1060\n",
      "Epoch 23/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2976 - acc: 0.1140 - val_loss: 2.2984 - val_acc: 0.1060\n",
      "Epoch 24/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2974 - acc: 0.1140 - val_loss: 2.2982 - val_acc: 0.1060\n",
      "Epoch 25/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2973 - acc: 0.1140 - val_loss: 2.2982 - val_acc: 0.1060\n",
      "Epoch 26/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2972 - acc: 0.1140 - val_loss: 2.2980 - val_acc: 0.1060\n",
      "Epoch 27/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2971 - acc: 0.1140 - val_loss: 2.2979 - val_acc: 0.1060\n",
      "Epoch 28/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2970 - acc: 0.1140 - val_loss: 2.2977 - val_acc: 0.1060\n",
      "Epoch 29/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2968 - acc: 0.1140 - val_loss: 2.2976 - val_acc: 0.1060\n",
      "Epoch 30/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2967 - acc: 0.1140 - val_loss: 2.2975 - val_acc: 0.1060\n",
      "Epoch 31/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2965 - acc: 0.1140 - val_loss: 2.2973 - val_acc: 0.1060\n",
      "Epoch 32/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2964 - acc: 0.1140 - val_loss: 2.2973 - val_acc: 0.1060\n",
      "Epoch 33/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2962 - acc: 0.1140 - val_loss: 2.2970 - val_acc: 0.1060\n",
      "Epoch 34/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2962 - acc: 0.1140 - val_loss: 2.2970 - val_acc: 0.1060\n",
      "Epoch 35/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2959 - acc: 0.1140 - val_loss: 2.2967 - val_acc: 0.1060\n",
      "Epoch 36/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2957 - acc: 0.1140 - val_loss: 2.2967 - val_acc: 0.1060\n",
      "Epoch 37/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2956 - acc: 0.1140 - val_loss: 2.2965 - val_acc: 0.1060\n",
      "Epoch 38/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2955 - acc: 0.1140 - val_loss: 2.2964 - val_acc: 0.1060\n",
      "Epoch 39/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2952 - acc: 0.1140 - val_loss: 2.2961 - val_acc: 0.1060\n",
      "Epoch 40/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2951 - acc: 0.1140 - val_loss: 2.2960 - val_acc: 0.1060\n",
      "Epoch 41/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2950 - acc: 0.1140 - val_loss: 2.2958 - val_acc: 0.1060\n",
      "Epoch 42/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2947 - acc: 0.1140 - val_loss: 2.2956 - val_acc: 0.1060\n",
      "Epoch 43/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2946 - acc: 0.1140 - val_loss: 2.2954 - val_acc: 0.1060\n",
      "Epoch 44/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2943 - acc: 0.1140 - val_loss: 2.2951 - val_acc: 0.1060\n",
      "Epoch 45/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2942 - acc: 0.1140 - val_loss: 2.2950 - val_acc: 0.1060\n",
      "Epoch 46/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2939 - acc: 0.1140 - val_loss: 2.2948 - val_acc: 0.1060\n",
      "Epoch 47/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2938 - acc: 0.1140 - val_loss: 2.2945 - val_acc: 0.1060\n",
      "Epoch 48/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 2.2936 - acc: 0.1140 - val_loss: 2.2944 - val_acc: 0.1060\n",
      "Epoch 49/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2933 - acc: 0.1141 - val_loss: 2.2941 - val_acc: 0.1060\n",
      "Epoch 50/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2931 - acc: 0.1141 - val_loss: 2.2939 - val_acc: 0.1060\n",
      "Epoch 51/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2929 - acc: 0.1140 - val_loss: 2.2938 - val_acc: 0.1060\n",
      "Epoch 52/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2926 - acc: 0.1140 - val_loss: 2.2933 - val_acc: 0.1060\n",
      "Epoch 53/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2924 - acc: 0.1143 - val_loss: 2.2932 - val_acc: 0.1060\n",
      "Epoch 54/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2922 - acc: 0.1141 - val_loss: 2.2931 - val_acc: 0.1060\n",
      "Epoch 55/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2918 - acc: 0.1140 - val_loss: 2.2925 - val_acc: 0.1060\n",
      "Epoch 56/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2916 - acc: 0.1141 - val_loss: 2.2923 - val_acc: 0.1060\n",
      "Epoch 57/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2913 - acc: 0.1145 - val_loss: 2.2921 - val_acc: 0.1060\n",
      "Epoch 58/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2910 - acc: 0.1140 - val_loss: 2.2917 - val_acc: 0.1060\n",
      "Epoch 59/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2906 - acc: 0.1142 - val_loss: 2.2915 - val_acc: 0.1060\n",
      "Epoch 60/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2904 - acc: 0.1142 - val_loss: 2.2911 - val_acc: 0.1060\n",
      "Epoch 61/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2901 - acc: 0.1145 - val_loss: 2.2908 - val_acc: 0.1060\n",
      "Epoch 62/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2897 - acc: 0.1148 - val_loss: 2.2904 - val_acc: 0.1060\n",
      "Epoch 63/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2894 - acc: 0.1149 - val_loss: 2.2901 - val_acc: 0.1060\n",
      "Epoch 64/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2890 - acc: 0.1153 - val_loss: 2.2897 - val_acc: 0.1060\n",
      "Epoch 65/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2886 - acc: 0.1153 - val_loss: 2.2891 - val_acc: 0.1060\n",
      "Epoch 66/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2882 - acc: 0.1200 - val_loss: 2.2889 - val_acc: 0.1060\n",
      "Epoch 67/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2877 - acc: 0.1171 - val_loss: 2.2884 - val_acc: 0.1060\n",
      "Epoch 68/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2874 - acc: 0.1205 - val_loss: 2.2880 - val_acc: 0.1060\n",
      "Epoch 69/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2869 - acc: 0.1183 - val_loss: 2.2874 - val_acc: 0.1061\n",
      "Epoch 70/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2865 - acc: 0.1214 - val_loss: 2.2871 - val_acc: 0.1060\n",
      "Epoch 71/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2860 - acc: 0.1222 - val_loss: 2.2867 - val_acc: 0.1060\n",
      "Epoch 72/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2855 - acc: 0.1219 - val_loss: 2.2861 - val_acc: 0.1060\n",
      "Epoch 73/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2849 - acc: 0.1237 - val_loss: 2.2854 - val_acc: 0.1060\n",
      "Epoch 74/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2844 - acc: 0.1255 - val_loss: 2.2849 - val_acc: 0.1074\n",
      "Epoch 75/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2837 - acc: 0.1267 - val_loss: 2.2842 - val_acc: 0.1948\n",
      "Epoch 76/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2832 - acc: 0.1397 - val_loss: 2.2837 - val_acc: 0.1097\n",
      "Epoch 77/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2825 - acc: 0.1364 - val_loss: 2.2831 - val_acc: 0.1163\n",
      "Epoch 78/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2819 - acc: 0.1352 - val_loss: 2.2823 - val_acc: 0.1340\n",
      "Epoch 79/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2812 - acc: 0.1446 - val_loss: 2.2815 - val_acc: 0.1377\n",
      "Epoch 80/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2804 - acc: 0.1440 - val_loss: 2.2809 - val_acc: 0.1221\n",
      "Epoch 81/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2796 - acc: 0.1486 - val_loss: 2.2800 - val_acc: 0.1558\n",
      "Epoch 82/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2790 - acc: 0.1539 - val_loss: 2.2793 - val_acc: 0.1320\n",
      "Epoch 83/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2782 - acc: 0.1521 - val_loss: 2.2785 - val_acc: 0.1642\n",
      "Epoch 84/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2772 - acc: 0.1626 - val_loss: 2.2774 - val_acc: 0.1765\n",
      "Epoch 85/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2764 - acc: 0.1707 - val_loss: 2.2768 - val_acc: 0.1258\n",
      "Epoch 86/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2754 - acc: 0.1660 - val_loss: 2.2758 - val_acc: 0.1590\n",
      "Epoch 87/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2745 - acc: 0.1700 - val_loss: 2.2746 - val_acc: 0.1644\n",
      "Epoch 88/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2734 - acc: 0.1753 - val_loss: 2.2733 - val_acc: 0.2168\n",
      "Epoch 89/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2722 - acc: 0.1826 - val_loss: 2.2723 - val_acc: 0.1913\n",
      "Epoch 90/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2710 - acc: 0.1915 - val_loss: 2.2716 - val_acc: 0.1358\n",
      "Epoch 91/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2699 - acc: 0.1858 - val_loss: 2.2699 - val_acc: 0.1701\n",
      "Epoch 92/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2686 - acc: 0.1949 - val_loss: 2.2689 - val_acc: 0.1453\n",
      "Epoch 93/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2671 - acc: 0.1974 - val_loss: 2.2674 - val_acc: 0.1628\n",
      "Epoch 94/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2656 - acc: 0.2020 - val_loss: 2.2655 - val_acc: 0.2179\n",
      "Epoch 95/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2640 - acc: 0.2067 - val_loss: 2.2638 - val_acc: 0.2375\n",
      "Epoch 96/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2625 - acc: 0.2100 - val_loss: 2.2621 - val_acc: 0.2374\n",
      "Epoch 97/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2608 - acc: 0.2197 - val_loss: 2.2607 - val_acc: 0.1891\n",
      "Epoch 98/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2590 - acc: 0.2197 - val_loss: 2.2585 - val_acc: 0.2568\n",
      "Epoch 99/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2569 - acc: 0.2255 - val_loss: 2.2567 - val_acc: 0.2142\n",
      "Epoch 100/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2546 - acc: 0.2252 - val_loss: 2.2543 - val_acc: 0.2491\n",
      "Epoch 101/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2525 - acc: 0.2295 - val_loss: 2.2519 - val_acc: 0.2727\n",
      "Epoch 102/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2504 - acc: 0.2372 - val_loss: 2.2499 - val_acc: 0.2272\n",
      "Epoch 103/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2482 - acc: 0.2370 - val_loss: 2.2472 - val_acc: 0.2572\n",
      "Epoch 104/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2452 - acc: 0.2435 - val_loss: 2.2446 - val_acc: 0.2591\n",
      "Epoch 105/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2426 - acc: 0.2425 - val_loss: 2.2419 - val_acc: 0.2217\n",
      "Epoch 106/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2398 - acc: 0.2455 - val_loss: 2.2391 - val_acc: 0.2190\n",
      "Epoch 107/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2367 - acc: 0.2506 - val_loss: 2.2350 - val_acc: 0.2724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.2329 - acc: 0.2478 - val_loss: 2.2316 - val_acc: 0.2641\n",
      "Epoch 109/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2296 - acc: 0.2574 - val_loss: 2.2277 - val_acc: 0.2630\n",
      "Epoch 110/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2260 - acc: 0.2544 - val_loss: 2.2242 - val_acc: 0.2565\n",
      "Epoch 111/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.2215 - acc: 0.2590 - val_loss: 2.2195 - val_acc: 0.2815\n",
      "Epoch 112/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.2171 - acc: 0.2622 - val_loss: 2.2147 - val_acc: 0.2911\n",
      "Epoch 113/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.2123 - acc: 0.2681 - val_loss: 2.2099 - val_acc: 0.2707\n",
      "Epoch 114/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.2075 - acc: 0.2673 - val_loss: 2.2071 - val_acc: 0.2358\n",
      "Epoch 115/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.2018 - acc: 0.2710 - val_loss: 2.1994 - val_acc: 0.2725\n",
      "Epoch 116/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.1963 - acc: 0.2711 - val_loss: 2.1934 - val_acc: 0.2908\n",
      "Epoch 117/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.1904 - acc: 0.2716 - val_loss: 2.1866 - val_acc: 0.3093\n",
      "Epoch 118/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.1841 - acc: 0.2780 - val_loss: 2.1799 - val_acc: 0.2984\n",
      "Epoch 119/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.1775 - acc: 0.2785 - val_loss: 2.1734 - val_acc: 0.2930\n",
      "Epoch 120/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.1700 - acc: 0.2774 - val_loss: 2.1650 - val_acc: 0.3008\n",
      "Epoch 121/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.1623 - acc: 0.2832 - val_loss: 2.1567 - val_acc: 0.3053\n",
      "Epoch 122/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.1541 - acc: 0.2825 - val_loss: 2.1478 - val_acc: 0.3243\n",
      "Epoch 123/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.1456 - acc: 0.2869 - val_loss: 2.1390 - val_acc: 0.3183\n",
      "Epoch 124/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.1368 - acc: 0.2908 - val_loss: 2.1298 - val_acc: 0.3217\n",
      "Epoch 125/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.1273 - acc: 0.2897 - val_loss: 2.1192 - val_acc: 0.3289\n",
      "Epoch 126/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.1170 - acc: 0.2941 - val_loss: 2.1082 - val_acc: 0.3182\n",
      "Epoch 127/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.1066 - acc: 0.2968 - val_loss: 2.1007 - val_acc: 0.3229\n",
      "Epoch 128/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.0961 - acc: 0.2995 - val_loss: 2.0861 - val_acc: 0.3289\n",
      "Epoch 129/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.0851 - acc: 0.2995 - val_loss: 2.0792 - val_acc: 0.3032\n",
      "Epoch 130/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.0723 - acc: 0.3052 - val_loss: 2.0601 - val_acc: 0.3578\n",
      "Epoch 131/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.0601 - acc: 0.3102 - val_loss: 2.0504 - val_acc: 0.3167\n",
      "Epoch 132/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.0482 - acc: 0.3088 - val_loss: 2.0347 - val_acc: 0.3310\n",
      "Epoch 133/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 2.0354 - acc: 0.3159 - val_loss: 2.0196 - val_acc: 0.3565\n",
      "Epoch 134/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.0228 - acc: 0.3188 - val_loss: 2.0064 - val_acc: 0.3633\n",
      "Epoch 135/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 2.0096 - acc: 0.3183 - val_loss: 1.9895 - val_acc: 0.3658\n",
      "Epoch 136/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9955 - acc: 0.3241 - val_loss: 1.9753 - val_acc: 0.3558\n",
      "Epoch 137/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9832 - acc: 0.3280 - val_loss: 1.9602 - val_acc: 0.3752\n",
      "Epoch 138/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9688 - acc: 0.3329 - val_loss: 1.9456 - val_acc: 0.3618\n",
      "Epoch 139/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9553 - acc: 0.3347 - val_loss: 1.9298 - val_acc: 0.3830\n",
      "Epoch 140/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.9426 - acc: 0.3392 - val_loss: 1.9263 - val_acc: 0.3931\n",
      "Epoch 141/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9282 - acc: 0.3409 - val_loss: 1.9055 - val_acc: 0.3962\n",
      "Epoch 142/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9168 - acc: 0.3463 - val_loss: 1.8869 - val_acc: 0.3954\n",
      "Epoch 143/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.9022 - acc: 0.3504 - val_loss: 1.8680 - val_acc: 0.3872\n",
      "Epoch 144/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8888 - acc: 0.3504 - val_loss: 1.8517 - val_acc: 0.4003\n",
      "Epoch 145/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8763 - acc: 0.3550 - val_loss: 1.8430 - val_acc: 0.4213\n",
      "Epoch 146/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8623 - acc: 0.3573 - val_loss: 1.8289 - val_acc: 0.4131\n",
      "Epoch 147/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8491 - acc: 0.3597 - val_loss: 1.8285 - val_acc: 0.3587\n",
      "Epoch 148/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8348 - acc: 0.3647 - val_loss: 1.7924 - val_acc: 0.4102\n",
      "Epoch 149/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8214 - acc: 0.3667 - val_loss: 1.7755 - val_acc: 0.4167\n",
      "Epoch 150/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.8108 - acc: 0.3692 - val_loss: 1.7744 - val_acc: 0.3995\n",
      "Epoch 151/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7969 - acc: 0.3727 - val_loss: 1.7446 - val_acc: 0.4168\n",
      "Epoch 152/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7799 - acc: 0.3755 - val_loss: 1.7618 - val_acc: 0.3855\n",
      "Epoch 153/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7697 - acc: 0.3776 - val_loss: 1.7137 - val_acc: 0.4248\n",
      "Epoch 154/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7566 - acc: 0.3803 - val_loss: 1.7152 - val_acc: 0.4091\n",
      "Epoch 155/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7452 - acc: 0.3843 - val_loss: 1.6856 - val_acc: 0.4258\n",
      "Epoch 156/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7289 - acc: 0.3893 - val_loss: 1.6682 - val_acc: 0.4432\n",
      "Epoch 157/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7165 - acc: 0.3902 - val_loss: 1.6624 - val_acc: 0.4553\n",
      "Epoch 158/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.7068 - acc: 0.3932 - val_loss: 1.6510 - val_acc: 0.4513\n",
      "Epoch 159/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6945 - acc: 0.3919 - val_loss: 1.6214 - val_acc: 0.4548\n",
      "Epoch 160/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6826 - acc: 0.3980 - val_loss: 1.6184 - val_acc: 0.4281\n",
      "Epoch 161/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6667 - acc: 0.4044 - val_loss: 1.5968 - val_acc: 0.4637\n",
      "Epoch 162/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6554 - acc: 0.4048 - val_loss: 1.5810 - val_acc: 0.4605\n",
      "Epoch 163/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6472 - acc: 0.4057 - val_loss: 1.5818 - val_acc: 0.4707\n",
      "Epoch 164/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6384 - acc: 0.4069 - val_loss: 1.5564 - val_acc: 0.4693\n",
      "Epoch 165/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6229 - acc: 0.4108 - val_loss: 1.5788 - val_acc: 0.4683\n",
      "Epoch 166/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.6209 - acc: 0.4131 - val_loss: 1.5479 - val_acc: 0.4824\n",
      "Epoch 167/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.6021 - acc: 0.4181 - val_loss: 1.5355 - val_acc: 0.4867\n",
      "Epoch 168/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5968 - acc: 0.4165 - val_loss: 1.5069 - val_acc: 0.4733\n",
      "Epoch 169/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5821 - acc: 0.4223 - val_loss: 1.5423 - val_acc: 0.4244\n",
      "Epoch 170/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5709 - acc: 0.4269 - val_loss: 1.4973 - val_acc: 0.4700\n",
      "Epoch 171/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5766 - acc: 0.4204 - val_loss: 1.4741 - val_acc: 0.5027\n",
      "Epoch 172/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.5634 - acc: 0.4268 - val_loss: 1.5059 - val_acc: 0.5019\n",
      "Epoch 173/250\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 1.5543 - acc: 0.4294 - val_loss: 1.5175 - val_acc: 0.4472\n",
      "Epoch 174/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.5434 - acc: 0.4346 - val_loss: 1.4641 - val_acc: 0.4701\n",
      "Epoch 175/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5313 - acc: 0.4338 - val_loss: 1.4366 - val_acc: 0.4976\n",
      "Epoch 176/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5239 - acc: 0.4366 - val_loss: 1.4322 - val_acc: 0.4920\n",
      "Epoch 177/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5195 - acc: 0.4379 - val_loss: 1.4179 - val_acc: 0.5058\n",
      "Epoch 178/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5083 - acc: 0.4429 - val_loss: 1.4059 - val_acc: 0.5200\n",
      "Epoch 179/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.5080 - acc: 0.4424 - val_loss: 1.4017 - val_acc: 0.5172\n",
      "Epoch 180/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.5027 - acc: 0.4452 - val_loss: 1.4389 - val_acc: 0.5196\n",
      "Epoch 181/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4899 - acc: 0.4487 - val_loss: 1.4427 - val_acc: 0.4693\n",
      "Epoch 182/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4911 - acc: 0.4477 - val_loss: 1.3862 - val_acc: 0.5122\n",
      "Epoch 183/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.4802 - acc: 0.4526 - val_loss: 1.4002 - val_acc: 0.4978\n",
      "Epoch 184/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4833 - acc: 0.4486 - val_loss: 1.3677 - val_acc: 0.5278\n",
      "Epoch 185/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4713 - acc: 0.4547 - val_loss: 1.3606 - val_acc: 0.5374\n",
      "Epoch 186/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4650 - acc: 0.4558 - val_loss: 1.3703 - val_acc: 0.5472\n",
      "Epoch 187/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4608 - acc: 0.4576 - val_loss: 1.3771 - val_acc: 0.4893\n",
      "Epoch 188/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4538 - acc: 0.4614 - val_loss: 1.3828 - val_acc: 0.4848\n",
      "Epoch 189/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.4516 - acc: 0.4621 - val_loss: 1.3499 - val_acc: 0.5390\n",
      "Epoch 190/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4472 - acc: 0.4661 - val_loss: 1.3527 - val_acc: 0.5332\n",
      "Epoch 191/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 1.4425 - acc: 0.4660 - val_loss: 1.3719 - val_acc: 0.4862\n",
      "Epoch 192/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4409 - acc: 0.4665 - val_loss: 1.3192 - val_acc: 0.5364\n",
      "Epoch 193/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4412 - acc: 0.4675 - val_loss: 1.3594 - val_acc: 0.5335\n",
      "Epoch 194/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4317 - acc: 0.4724 - val_loss: 1.3961 - val_acc: 0.4814\n",
      "Epoch 195/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4256 - acc: 0.4724 - val_loss: 1.3071 - val_acc: 0.5710\n",
      "Epoch 196/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.4246 - acc: 0.4741 - val_loss: 1.3272 - val_acc: 0.5214\n",
      "Epoch 197/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4234 - acc: 0.4775 - val_loss: 1.2933 - val_acc: 0.5476\n",
      "Epoch 198/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4138 - acc: 0.4781 - val_loss: 1.3715 - val_acc: 0.4903\n",
      "Epoch 199/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4154 - acc: 0.4798 - val_loss: 1.2833 - val_acc: 0.5514\n",
      "Epoch 200/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4078 - acc: 0.4825 - val_loss: 1.2829 - val_acc: 0.5641\n",
      "Epoch 201/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4038 - acc: 0.4830 - val_loss: 1.3660 - val_acc: 0.4971\n",
      "Epoch 202/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4071 - acc: 0.4848 - val_loss: 1.3394 - val_acc: 0.5057\n",
      "Epoch 203/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.4035 - acc: 0.4877 - val_loss: 1.2893 - val_acc: 0.5654\n",
      "Epoch 204/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 1.3883 - acc: 0.4916 - val_loss: 1.2604 - val_acc: 0.5867\n",
      "Epoch 205/250\n",
      "48000/48000 [==============================] - 18s 369us/step - loss: 1.3770 - acc: 0.4971 - val_loss: 1.3014 - val_acc: 0.5290\n",
      "Epoch 206/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 1.3765 - acc: 0.4972 - val_loss: 1.2642 - val_acc: 0.5453\n",
      "Epoch 207/250\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 1.3825 - acc: 0.4951 - val_loss: 1.2684 - val_acc: 0.5583\n",
      "Epoch 208/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3652 - acc: 0.5029 - val_loss: 1.2732 - val_acc: 0.5475\n",
      "Epoch 209/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3671 - acc: 0.5032 - val_loss: 1.2605 - val_acc: 0.5497\n",
      "Epoch 210/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3733 - acc: 0.5025 - val_loss: 1.2631 - val_acc: 0.5546\n",
      "Epoch 211/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3541 - acc: 0.5092 - val_loss: 1.2325 - val_acc: 0.5696\n",
      "Epoch 212/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 1.3553 - acc: 0.5094 - val_loss: 1.2047 - val_acc: 0.6148\n",
      "Epoch 213/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3435 - acc: 0.5162 - val_loss: 1.4058 - val_acc: 0.4703\n",
      "Epoch 214/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3488 - acc: 0.5134 - val_loss: 1.2746 - val_acc: 0.5690\n",
      "Epoch 215/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3329 - acc: 0.5196 - val_loss: 1.2210 - val_acc: 0.5842\n",
      "Epoch 216/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3319 - acc: 0.5180 - val_loss: 1.2574 - val_acc: 0.5503\n",
      "Epoch 217/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.3301 - acc: 0.5216 - val_loss: 1.1858 - val_acc: 0.6163\n",
      "Epoch 218/250\n",
      "48000/48000 [==============================] - 2s 34us/step - loss: 1.3098 - acc: 0.5303 - val_loss: 1.1883 - val_acc: 0.5918\n",
      "Epoch 219/250\n",
      "48000/48000 [==============================] - 4s 73us/step - loss: 1.3076 - acc: 0.5314 - val_loss: 1.1706 - val_acc: 0.6324\n",
      "Epoch 220/250\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 1.3098 - acc: 0.5290 - val_loss: 1.1958 - val_acc: 0.5944\n",
      "Epoch 221/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2980 - acc: 0.5337 - val_loss: 1.1507 - val_acc: 0.6374\n",
      "Epoch 222/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2913 - acc: 0.5374 - val_loss: 1.2364 - val_acc: 0.6027\n",
      "Epoch 223/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2867 - acc: 0.5433 - val_loss: 1.1680 - val_acc: 0.5967\n",
      "Epoch 224/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2903 - acc: 0.5395 - val_loss: 1.1623 - val_acc: 0.6254\n",
      "Epoch 225/250\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 1.2762 - acc: 0.5455 - val_loss: 1.1729 - val_acc: 0.5973\n",
      "Epoch 226/250\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 1.2573 - acc: 0.5524 - val_loss: 1.1725 - val_acc: 0.6398\n",
      "Epoch 227/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2631 - acc: 0.5490 - val_loss: 1.1198 - val_acc: 0.6385\n",
      "Epoch 228/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2523 - acc: 0.5553 - val_loss: 1.1285 - val_acc: 0.6623\n",
      "Epoch 229/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2410 - acc: 0.5578 - val_loss: 1.1443 - val_acc: 0.6007\n",
      "Epoch 230/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2448 - acc: 0.5587 - val_loss: 1.0883 - val_acc: 0.6522\n",
      "Epoch 231/250\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 1.2417 - acc: 0.5605 - val_loss: 1.1246 - val_acc: 0.6103\n",
      "Epoch 232/250\n",
      "48000/48000 [==============================] - 3s 73us/step - loss: 1.2322 - acc: 0.5611 - val_loss: 1.0954 - val_acc: 0.6525\n",
      "Epoch 233/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2138 - acc: 0.5689 - val_loss: 1.0945 - val_acc: 0.6288\n",
      "Epoch 234/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.2194 - acc: 0.5672 - val_loss: 1.0884 - val_acc: 0.6523\n",
      "Epoch 235/250\n",
      "48000/48000 [==============================] - 2s 33us/step - loss: 1.2136 - acc: 0.5695 - val_loss: 1.1150 - val_acc: 0.6343\n",
      "Epoch 236/250\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 1.1999 - acc: 0.5785 - val_loss: 1.0637 - val_acc: 0.6552\n",
      "Epoch 237/250\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 1.1924 - acc: 0.5790 - val_loss: 1.1864 - val_acc: 0.5648\n",
      "Epoch 238/250\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 1.1868 - acc: 0.5786 - val_loss: 1.0478 - val_acc: 0.6455\n",
      "Epoch 239/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1779 - acc: 0.5864 - val_loss: 1.0464 - val_acc: 0.6823\n",
      "Epoch 240/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1793 - acc: 0.5821 - val_loss: 1.0694 - val_acc: 0.6275\n",
      "Epoch 241/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1696 - acc: 0.5872 - val_loss: 1.0236 - val_acc: 0.6922\n",
      "Epoch 242/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1574 - acc: 0.5906 - val_loss: 1.0485 - val_acc: 0.6665\n",
      "Epoch 243/250\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 1.1611 - acc: 0.5900 - val_loss: 1.0105 - val_acc: 0.6911\n",
      "Epoch 244/250\n",
      "48000/48000 [==============================] - 4s 79us/step - loss: 1.1564 - acc: 0.5896 - val_loss: 0.9930 - val_acc: 0.6876\n",
      "Epoch 245/250\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 1.1479 - acc: 0.5929 - val_loss: 1.0212 - val_acc: 0.6731\n",
      "Epoch 246/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1352 - acc: 0.5996 - val_loss: 1.0096 - val_acc: 0.6630\n",
      "Epoch 247/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1407 - acc: 0.5973 - val_loss: 0.9912 - val_acc: 0.6793\n",
      "Epoch 248/250\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1365 - acc: 0.5983 - val_loss: 0.9746 - val_acc: 0.7032\n",
      "Epoch 249/250\n",
      "48000/48000 [==============================] - 4s 75us/step - loss: 1.1175 - acc: 0.6073 - val_loss: 0.9750 - val_acc: 0.7056\n",
      "Epoch 250/250\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 1.1216 - acc: 0.6056 - val_loss: 1.0245 - val_acc: 0.6520\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "Test Score: 7.283060509490967\n",
      "Test accuracy: 0.5195\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(n_hidden,input_shape=(reshaped,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "history=model.fit(x_train,y_train,batch_size=batch_size,epochs=nb_epoch,verbose=1,validation_split=validation_split)\n",
    "score=model.evaluate(x_test,y_test,verbose=1)\n",
    "print(\"Test Score:\",score[0])\n",
    "print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
